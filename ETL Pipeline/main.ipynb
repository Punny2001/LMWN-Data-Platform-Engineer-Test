{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import duckdb\n",
    "from datetime import datetime, timedelta, time\n",
    "import glob\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "SOURCE_DIR = \"data\"\n",
    "PATH: str = CURRENT_PATH+\"/\"+SOURCE_DIR\n",
    "\n",
    "forced_date = \"2022-02-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig( \n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_date(date: str):\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    yesterday_date = date - timedelta(days=1)\n",
    "    return yesterday_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parquet(forced_date: str, pipeline_type: int):\n",
    "    previous_date = extract_previous_date(forced_date)\n",
    "    year = previous_date.year\n",
    "    month = previous_date.month if previous_date.month > 9 else \"0\"+str(previous_date.month)\n",
    "\n",
    "    if pipeline_type == 1:\n",
    "        df = pd.read_parquet(f\"{PATH}/fhvhv_tripdata_{year}-{month}.parquet\", columns=[\"request_datetime\"])\n",
    "    else:\n",
    "        reg_path = sorted( glob.glob(f'{PATH}/*{year}*.parquet'))\n",
    "        until_file_path = f'{PATH}/fhvhv_tripdata_2022-{month}.parquet'\n",
    "        index = 0\n",
    "        fianl_file_path = []\n",
    "        while reg_path[index] != until_file_path:\n",
    "            fianl_file_path.append(reg_path[index])\n",
    "            index += 1\n",
    "            \n",
    "        fianl_file_path.append(until_file_path)\n",
    "\n",
    "        df_list = [pd.read_parquet(file, columns=[\"PULocationID\", \"request_datetime\"]) for file in fianl_file_path]\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_table_existed(database_name: str, table_name: str):\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "    result = conn.execute(f\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_name = '{table_name}'\n",
    "    \"\"\").fetchall()\n",
    "    conn.close()\n",
    "    return 1 if len(result) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_1st(forced_date):\n",
    "    df = extract_parquet(forced_date, 1)\n",
    "\n",
    "    previous_date = extract_previous_date(forced_date)\n",
    "    transformed_df = df[df[\"request_datetime\"]==previous_date]\n",
    "\n",
    "    now = datetime.now()\n",
    "    hour = now.hour\n",
    "    minute = now.minute\n",
    "    second = now.second\n",
    "\n",
    "    calculated_at = datetime.combine(previous_date.date(), time(hour, minute, second))\n",
    "\n",
    "    transformed_data = {\n",
    "        \"transaction_date\": [previous_date],\n",
    "        \"total_transactions\": [transformed_df.shape[0]],\n",
    "        \"calculated_at\": [calculated_at]\n",
    "    }\n",
    "\n",
    "    processed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "    pk = \"transaction_date\"\n",
    "    database_name = \"processed\"\n",
    "    table_name = \"daily_transaction\"\n",
    "    is_table_existed = check_table_existed(database_name, table_name)\n",
    "    query_string = \"\"\n",
    "\n",
    "    if is_table_existed:\n",
    "        query_string = f\"\"\"\n",
    "            DELETE FROM {table_name}\n",
    "            WHERE {pk} = '{previous_date}';\n",
    "\n",
    "            INSERT INTO {table_name} \n",
    "            SELECT *\n",
    "            FROM processed_df;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        query_string = f\"\"\"\n",
    "            CREATE TABLE {table_name} (\n",
    "                transaction_date DATE,\n",
    "                total_transactions INT,\n",
    "                calculated_at TIMESTAMP,\n",
    "                PRIMARY KEY ({pk})\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name}\n",
    "            SELECT * FROM processed_df\n",
    "        \"\"\"\n",
    "\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "\n",
    "    conn.execute(query_string)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_2nd(forced_date):\n",
    "    df = extract_parquet(forced_date, 2)\n",
    "\n",
    "    transformed_df = df[df[\"request_datetime\"]<forced_date]\n",
    "    transformed_df = transformed_df.groupby(\"PULocationID\").size().reset_index(name=\"count\")\n",
    "    transformed_df.rename(columns={\"PULocationID\": \"taxi_zone_id\"}, inplace=True)\n",
    "    transformed_df[\"rank\"] = transformed_df[\"count\"].rank(method=\"dense\", ascending=False)\n",
    "    transformed_df[\"rank\"] = transformed_df[\"rank\"].astype(int)\n",
    "    transformed_df = transformed_df[transformed_df[\"rank\"]<=5]\n",
    "\n",
    "    forced_date = datetime.strptime(forced_date, \"%Y-%m-%d\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    hour = now.hour\n",
    "    minute = now.minute\n",
    "    second = now.second\n",
    "\n",
    "    calculated_at = datetime.combine(forced_date.date(), time(hour, minute, second))\n",
    "\n",
    "    transformed_df[\"calculated_at\"] = calculated_at\n",
    "\n",
    "    processed_df = transformed_df[[\"taxi_zone_id\", \"rank\", \"calculated_at\"]]\n",
    "    \n",
    "    pk = [\"taxi_zone_id\", \"calculated_at\"]\n",
    "    pk_type = [\"INT\", \"DATETIME\"]\n",
    "    database_name = \"processed\"\n",
    "    table_name = \"daily_topfive_taxi_zone\"\n",
    "    is_table_existed = check_table_existed(database_name, table_name)\n",
    "    query_string = \"\"\n",
    "    where_condition = \" AND \".join(\n",
    "        f\"CAST(incoming.{column} AS DATE) = CAST(current.{column} AS DATE)\" if pk_type[index] == \"DATETIME\" \n",
    "        else f\"incoming.{column} = current.{column}\"\n",
    "        for index, column in enumerate(pk)\n",
    "    )\n",
    "    \n",
    "\n",
    "    if is_table_existed:\n",
    "        query_string = f\"\"\"\n",
    "            DELETE FROM {table_name} current\n",
    "            WHERE EXISTS (\n",
    "                SELECT {', '.join(pk)}\n",
    "                FROM processed_df incoming\n",
    "                WHERE {where_condition}\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name} \n",
    "            SELECT *\n",
    "            FROM processed_df;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        query_string = f\"\"\"\n",
    "            CREATE TABLE {table_name} (\n",
    "                taxi_zone_id INT,\n",
    "                rank INT,\n",
    "                calculated_at TIMESTAMP,\n",
    "                PRIMARY KEY ({','.join(pk)})\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name}\n",
    "            SELECT * FROM processed_df\n",
    "        \"\"\"\n",
    "\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "\n",
    "    conn.execute(query_string)\n",
    "\n",
    "    conn.close()\n",
    "    return 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
