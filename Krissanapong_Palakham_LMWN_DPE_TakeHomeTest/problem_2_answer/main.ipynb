{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta, time\n",
    "import glob\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.operators.empty import EmptyOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "SOURCE_DIR = \"data\"\n",
    "PATH: str = CURRENT_PATH+\"/\"+SOURCE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_date(date: str):\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    yesterday_date = date - timedelta(days=1)\n",
    "    return yesterday_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parquet(forced_date: str, pipeline_type: int):\n",
    "    previous_date = extract_previous_date(forced_date)\n",
    "    year = previous_date.year\n",
    "    month = previous_date.month if previous_date.month > 9 else \"0\"+str(previous_date.month)\n",
    "\n",
    "    if pipeline_type == 1:\n",
    "        df = pd.read_parquet(f\"{PATH}/fhvhv_tripdata_{year}-{month}.parquet\", columns=[\"request_datetime\"])\n",
    "    else:\n",
    "        reg_path = sorted( glob.glob(f'{PATH}/*{year}*.parquet'))\n",
    "        until_file_path = f'{PATH}/fhvhv_tripdata_{year}-{month}.parquet'\n",
    "        index = 0\n",
    "        fianl_file_path = []\n",
    "        while reg_path[index] != until_file_path:\n",
    "            fianl_file_path.append(reg_path[index])\n",
    "            index += 1\n",
    "            \n",
    "        fianl_file_path.append(until_file_path)\n",
    "\n",
    "        df_list = [pd.read_parquet(file, columns=[\"PULocationID\", \"request_datetime\"]) for file in fianl_file_path]\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_table_existed(database_name: str, table_name: str):\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "    result = conn.execute(f\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_name = '{table_name}'\n",
    "    \"\"\").fetchall()\n",
    "    conn.close()\n",
    "    return 1 if len(result) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_1st(forced_date):\n",
    "    df = extract_parquet(forced_date, 1)\n",
    "\n",
    "    previous_date = extract_previous_date(forced_date)\n",
    "    transformed_df = df[df[\"request_datetime\"]==previous_date]\n",
    "\n",
    "    now = datetime.now()\n",
    "    hour = now.hour\n",
    "    minute = now.minute\n",
    "    second = now.second\n",
    "\n",
    "    calculated_at = datetime.combine(previous_date.date(), time(hour, minute, second))\n",
    "\n",
    "    transformed_data = {\n",
    "        \"transaction_date\": [previous_date],\n",
    "        \"total_transactions\": [transformed_df.shape[0]],\n",
    "        \"calculated_at\": [calculated_at]\n",
    "    }\n",
    "\n",
    "    processed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "    pk = \"transaction_date\"\n",
    "    database_name = \"processed\"\n",
    "    table_name = \"daily_transaction\"\n",
    "    is_table_existed = check_table_existed(database_name, table_name)\n",
    "    query_string = \"\"\n",
    "\n",
    "    if is_table_existed:\n",
    "        query_string = f\"\"\"\n",
    "            DELETE FROM {table_name}\n",
    "            WHERE {pk} = '{previous_date}';\n",
    "\n",
    "            INSERT INTO {table_name} \n",
    "            SELECT *\n",
    "            FROM processed_df;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        query_string = f\"\"\"\n",
    "            CREATE TABLE {table_name} (\n",
    "                transaction_date DATE,\n",
    "                total_transactions INT,\n",
    "                calculated_at TIMESTAMP,\n",
    "                PRIMARY KEY ({pk})\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name}\n",
    "            SELECT * FROM processed_df\n",
    "        \"\"\"\n",
    "\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "\n",
    "    conn.execute(query_string)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_2nd(forced_date):\n",
    "    df = extract_parquet(forced_date, 2)\n",
    "\n",
    "    transformed_df = df[df[\"request_datetime\"]<forced_date]\n",
    "    transformed_df = transformed_df.groupby(\"PULocationID\").size().reset_index(name=\"count\")\n",
    "    transformed_df.rename(columns={\"PULocationID\": \"taxi_zone_id\"}, inplace=True)\n",
    "    transformed_df[\"rank\"] = transformed_df[\"count\"].rank(method=\"dense\", ascending=False)\n",
    "    transformed_df[\"rank\"] = transformed_df[\"rank\"].astype(int)\n",
    "    transformed_df = transformed_df[transformed_df[\"rank\"]<=5]\n",
    "\n",
    "    forced_date = datetime.strptime(forced_date, \"%Y-%m-%d\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    hour = now.hour\n",
    "    minute = now.minute\n",
    "    second = now.second\n",
    "\n",
    "    calculated_at = datetime.combine(forced_date.date(), time(hour, minute, second))\n",
    "\n",
    "    transformed_df[\"calculated_at\"] = calculated_at\n",
    "\n",
    "    processed_df = transformed_df[[\"taxi_zone_id\", \"rank\", \"calculated_at\"]]\n",
    "    \n",
    "    pk = [\"taxi_zone_id\", \"calculated_at\"]\n",
    "    pk_type = [\"INT\", \"DATETIME\"]\n",
    "    database_name = \"processed\"\n",
    "    table_name = \"daily_topfive_taxi_zone\"\n",
    "    is_table_existed = check_table_existed(database_name, table_name)\n",
    "    query_string = \"\"\n",
    "    where_condition = \" AND \".join(\n",
    "        f\"CAST(incoming.{column} AS DATE) = CAST(current.{column} AS DATE)\" if pk_type[index] == \"DATETIME\" \n",
    "        else f\"incoming.{column} = current.{column}\"\n",
    "        for index, column in enumerate(pk)\n",
    "    )\n",
    "    \n",
    "\n",
    "    if is_table_existed:\n",
    "        query_string = f\"\"\"\n",
    "            DELETE FROM {table_name} current\n",
    "            WHERE EXISTS (\n",
    "                SELECT {', '.join(pk)}\n",
    "                FROM processed_df incoming\n",
    "                WHERE {where_condition}\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name} \n",
    "            SELECT *\n",
    "            FROM processed_df;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        query_string = f\"\"\"\n",
    "            CREATE TABLE {table_name} (\n",
    "                taxi_zone_id INT,\n",
    "                rank INT,\n",
    "                calculated_at TIMESTAMP,\n",
    "                PRIMARY KEY ({','.join(pk)})\n",
    "            );\n",
    "\n",
    "            INSERT INTO {table_name}\n",
    "            SELECT * FROM processed_df\n",
    "        \"\"\"\n",
    "\n",
    "    conn = duckdb.connect(f\"{database_name}.duckdb\")\n",
    "\n",
    "    conn.execute(query_string)\n",
    "\n",
    "    conn.close()\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(EmptyOperator): end_process>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_args ={ \n",
    "    'owner': 'Krissanapong',\n",
    "    'start_date': \"2023-01-01\"\n",
    "}\n",
    "\n",
    "dag = DAG(dag_id=\"vehicle_trip\", default_args=default_args, schedule='0 0 * * *')\n",
    "\n",
    "start_process = EmptyOperator(\n",
    "    task_id=\"start_process\",\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "run_1st_pipeline = PythonOperator(\n",
    "    task_id=\"process_1st_pipeline\",\n",
    "    python_callable=pipeline_1st,\n",
    "    op_kwargs={'forced_date': '{{ ds }}'},\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "run_2nd_pipeline = PythonOperator(\n",
    "    task_id=\"process_2nd_pipeline\",\n",
    "    python_callable=pipeline_2nd,\n",
    "    op_kwargs={'forced_date': '{{ ds }}'},\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "end_process = EmptyOperator(\n",
    "    task_id=\"end_process\",\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "start_process >> [run_1st_pipeline, run_2nd_pipeline] >> end_process\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1st('2023-03-20')\n",
    "pipeline_2nd('2023-01-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(\"processed.duckdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>calculated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-31 23:53:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>22</td>\n",
       "      <td>2023-03-19 23:55:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_date  total_transactions       calculated_at\n",
       "0       2023-05-31                   9 2023-05-31 23:53:37\n",
       "1       2023-03-19                  22 2023-03-19 23:55:42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = conn.execute(\"SELECT * FROM daily_transaction ORDER BY calculated_at DESC LIMIT 100\").fetchdf()\n",
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_zone_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>calculated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-15 23:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15 23:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-15 23:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-15 23:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-15 23:55:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-01 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-01 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 23:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-01 23:55:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   taxi_zone_id  rank       calculated_at\n",
       "0            61     4 2023-01-15 23:55:44\n",
       "1            79     3 2023-01-15 23:55:44\n",
       "2           132     1 2023-01-15 23:55:44\n",
       "3           138     2 2023-01-15 23:55:44\n",
       "4           230     5 2023-01-15 23:55:44\n",
       "5            61     5 2023-01-01 23:55:11\n",
       "6            79     3 2023-01-01 23:55:11\n",
       "7           132     2 2023-01-01 23:55:11\n",
       "8           138     1 2023-01-01 23:55:11\n",
       "9           230     4 2023-01-01 23:55:11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = conn.execute(\"SELECT * FROM daily_topfive_taxi_zone ORDER BY calculated_at DESC LIMIT 100\").fetchdf()\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
